{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ/B1kqOefnzLlht5Nr/Cb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokKaturi/NLP/blob/main/Text%20Summarization%20using%20spaCY%20and%20Genism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "SN3-GW3ngbMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy  #removing stopwords\n",
        "from string import punctuation #removing punctuations\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import heapq\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "from gensim.summarization import summarize\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
      ],
      "metadata": {
        "id": "TVmaGDLetjKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ebf2c2-31b7-4a68-8443-fbde67afd15f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the file "
      ],
      "metadata": {
        "id": "Zqtb9KY0gf_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./spaceX_DP.txt\") as f: #opening text file \n",
        "    reviews = f.read() #reading the text file"
      ],
      "metadata": {
        "id": "ZmSSd4d9OP_1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst=[]\n",
        "for token in reviews.split():\n",
        "    if token.lower() not in stopwords:\n",
        "        lst.append(token)\n",
        "\n"
      ],
      "metadata": {
        "id": "27Q0id1bsh0Z"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Punctuations"
      ],
      "metadata": {
        "id": "HV7wNgBSwJ1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_after_punctuation = reviews_after_stopwords.translate(str.maketrans('','',punctuation))"
      ],
      "metadata": {
        "id": "7LMZHAxPs1eY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_after_punctuation= re.sub(r'[^\\w\\s]', ' ',reviews_after_punctuation ).lower()"
      ],
      "metadata": {
        "id": "KbOAmBEyF91S"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the 'SpaceX.txt' corpus."
      ],
      "metadata": {
        "id": "GXgRTIDywlZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "4kcQv-k3wUmf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(reviews_after_punctuation)"
      ],
      "metadata": {
        "id": "SbERA7JpD_5L"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the maximum frequency as 'word_frequencies[word]=\n",
        "(word_frequencies[word]/maximum_frequency)."
      ],
      "metadata": {
        "id": "RqRg1-mOM9xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = [tokens.count(string) for string in tokens]"
      ],
      "metadata": {
        "id": "tBA1ra_FGXFZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the sentences. Generate the sentence_scores. Score every sentence\n",
        "based on number of words."
      ],
      "metadata": {
        "id": "fe6SW-ZaUAAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the sentences. Generate the sentence_scores. Score every sentence\n",
        "based on number of words."
      ],
      "metadata": {
        "id": "Lo6PgNDWXvaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_score=[count/max(word_frequencies) for count in word_frequencies ]"
      ],
      "metadata": {
        "id": "0aMMb02iImG5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_value=dict(zip(tokens,word_score))"
      ],
      "metadata": {
        "id": "wXJ_uzfjX_3o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "id": "Jx-4Mr2zJvuM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = sent_tokenize(reviews)"
      ],
      "metadata": {
        "id": "O21kjW91Ig9c"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_score = {}\n",
        "for sentence in sent_tokens:\n",
        "  for word in sentence.lower():\n",
        "    if word in word_value.keys():\n",
        "      if len(sentence.split(' '))< 30:\n",
        "        if sentence not in sentence_score.keys():\n",
        "          sentence_score[sentence] = word_value[word]\n",
        "        else:\n",
        "            sentence_score[sentence] +=word_value[word]\n",
        "\n"
      ],
      "metadata": {
        "id": "L3cxorbwJ1X2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nlargest from heapq"
      ],
      "metadata": {
        "id": "JiabzitwOnvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_sentences  = heapq.nlargest(10,sentence_score,key=sentence_score.get)"
      ],
      "metadata": {
        "id": "jFXvUg1nORIp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = [word for word in summarized_sentences]\n",
        "summary=''.join(sen)"
      ],
      "metadata": {
        "id": "QRYE71SwPR6X"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summary_gen = summarize(reviews)"
      ],
      "metadata": {
        "id": "cJAYkRVkPpF7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison between Gensim and Spacy's output\n",
        "print(\"Spacy's Summary Length:\",len(summary))\n",
        "print(\"Gensim's Summary Length:\",len(summary_gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqWeqpQyPqEK",
        "outputId": "03377e0f-6bda-44bc-b1ec-c383ae29e35c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spacy's Summary Length: 1714\n",
            "Gensim's Summary Length: 43752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the summary in 250 words.\n",
        "summarize(reviews, word_count=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "ZdjRSei0Qq2b",
        "outputId": "2bd63990-f2f9-46be-9ba4-8a9871565e59"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Musk, in a presentation here Saturday, said his goal of building a “rapidly reusable spacecraft” here would lead to the fulfillment of his ultimate goal of creating “a city on Mars.” But first, he’ll need to pull off another improbable feat, building a private, commercial spaceport here, in what the top local elected official called a “mind-boggling” juxtaposition: SpaceX, one of the hottest companies in the world, led by a Silicon Valley celebrity with nearly 29 million Twitter followers, building a rocket in a border town where nearly a third of the residents live below the poverty line.“I never in a million years would have imagined it,” said Cameron County Judge Eddie Treviño Jr. Five years ago, SpaceX started building a launchpad here, hauling in dirt by the ton, that would allow the company a measure of freedom without the restraints that come with shooting rockets off from government sites, such as Cape Canaveral or Vandenberg Air Force Base in California, where several other companies operate.\\nSpaceX is better than that.”While many of their neighbors, who don’t live in Boca Chica year round, have taken the offer, they continue to try to negotiate.To Treviño and other local officials, moving a few residents is a small price to pay to make way for SpaceX and its starry ambitions.“We have to think big-picture,” Treviño said.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis"
      ],
      "metadata": {
        "id": "9LA9GcKBQyJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11J1PBrvQu3m",
        "outputId": "453e9bd3-72b4-484a-de2b-e7b202bcb2ff"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from vaderSentiment) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (4.0.0)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the file\n",
        "space_text= open('./SpaceX.txt').read()\n",
        "\n"
      ],
      "metadata": {
        "id": "owYWlbIRQ2r5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_scores(sentence):\n",
        " \n",
        "    # Create a SentimentIntensityAnalyzer object.\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        " \n",
        "    # polarity_scores method of SentimentIntensityAnalyzer\n",
        "    # object gives a sentiment dictionary.\n",
        "    # which contains pos, neg, neu, and compound scores.\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "     \n",
        "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
        "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
        "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
        "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
        " \n",
        "    print(\"Sentence Overall Rated As\", end = \" \")\n",
        " \n",
        "    # decide sentiment as positive, negative and neutral\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        print(\"Positive\")\n",
        " \n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "        print(\"Negative\")\n",
        " \n",
        "    else :\n",
        "        print(\"Neutral\")\n",
        " \n",
        " \n",
        "   \n",
        "# Driver code\n",
        "if __name__ == \"__main__\" :\n",
        "  sentiment_scores(space_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjaqcmDBQ-KA",
        "outputId": "8ec5c8c0-0718-4d17-d963-3787a2f9938e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall sentiment dictionary is :  {'neg': 0.061, 'neu': 0.863, 'pos': 0.076, 'compound': 0.5999}\n",
            "sentence was rated as  6.1 % Negative\n",
            "sentence was rated as  86.3 % Neutral\n",
            "sentence was rated as  7.6 % Positive\n",
            "Sentence Overall Rated As Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is the text more ‘subjective’ or more ‘objective’?"
      ],
      "metadata": {
        "id": "2Dq9L45PSIIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the sentences are neutral.Here, text is formal and doesn't have a strong opinion on anything. Hence, the text is more objective."
      ],
      "metadata": {
        "id": "I2eYHPxxSKQp"
      }
    }
  ]
}